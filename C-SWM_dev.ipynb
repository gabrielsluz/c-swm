{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Making new env: ShapesTrain-v0\n",
      "iter 0\n",
      "INFO: Making new env: ShapesEval-v0\n",
      "iter 0\n",
      "iter 10\n",
      "iter 20\n",
      "iter 30\n",
      "iter 40\n",
      "iter 50\n",
      "iter 60\n",
      "iter 70\n",
      "iter 80\n",
      "iter 90\n"
     ]
    }
   ],
   "source": [
    "!python data_gen/env.py --env_id ShapesTrain-v0 --fname data/shapes_train.h5 --num_episodes 10 --seed 1\n",
    "!python data_gen/env.py --env_id ShapesEval-v0 --fname data/shapes_eval.h5 --num_episodes 100 --seed 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch: 1 [0/1000 (0%)]\tLoss: 0.001106\n",
      "====> Epoch: 1 Average loss: 0.001106\n",
      "Epoch: 2 [0/1000 (0%)]\tLoss: 0.015802\n",
      "====> Epoch: 2 Average loss: 0.015802\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset data/shapes_train.h5 --encoder small --name shapes --epochs 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slot Attention dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Traceback (most recent call last):\n",
      "  File \"train_slot_attn.py\", line 184, in <module>\n",
      "    loss = model.contrastive_loss(*data_batch)\n",
      "  File \"/Users/zeba/Desktop/POC/c-swm/modules_slot_attn.py\", line 107, in contrastive_loss\n",
      "    state = self.obj_encoder(objs)\n",
      "  File \"/anaconda3/envs/c-swm/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/zeba/Desktop/POC/c-swm/modules_slot_attn.py\", line 519, in forward\n",
      "    return super(EncoderSlotAttention, self).forward(ins)\n",
      "  File \"/Users/zeba/Desktop/POC/c-swm/slot_attention/slot_attention.py\", line 41, in forward\n",
      "    inputs = self.norm_input(inputs)        \n",
      "  File \"/anaconda3/envs/c-swm/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/anaconda3/envs/c-swm/lib/python3.6/site-packages/torch/nn/modules/normalization.py\", line 152, in forward\n",
      "    input, self.normalized_shape, self.weight, self.bias, self.eps)\n",
      "  File \"/anaconda3/envs/c-swm/lib/python3.6/site-packages/torch/nn/functional.py\", line 1682, in layer_norm\n",
      "    torch.backends.cudnn.enabled)\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1000, 5, 25]\n"
     ]
    }
   ],
   "source": [
    "!python train_slot_attn.py --dataset data/shapes_train.h5 --encoder small --name shapes --epochs 1 --use_slot_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch: 1 [0/1000 (0%)]\tLoss: 0.001106\n",
      "====> Epoch: 1 Average loss: 0.001106\n"
     ]
    }
   ],
   "source": [
    "!python train_slot_attn.py --dataset data/shapes_train.h5 --encoder small --name shapes --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
